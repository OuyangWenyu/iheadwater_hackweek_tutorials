{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c408032-c93e-4137-a98e-957767d22c9d",
   "metadata": {},
   "source": [
    "# PyTorch中的Tensor基础\n",
    "\n",
    "PyTorch的tensor和Numpy的Array，Pandas的Series和Dataframe类似，是了解应用这些代码库的基础，这里首先简单快速地了解Tensor及其在PyTorch的作用。\n",
    "\n",
    "主要参考：\n",
    "\n",
    "- TENSORS\n",
    "- Speed Up your Algorithms Part 1 — PyTorch\n",
    "- PyTorch 101, Part 1: Understanding Graphs, Automatic Differentiation and Autograd\n",
    "\n",
    "## 快速了解Tensor\n",
    "pytorch作为NumPy的替代品，可以利用GPU的性能进行计算；可作为一个高灵活性、速度快的深度学习平台。\n",
    "\n",
    "Tensor（张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。因此经常看到把numpy的数组包装为tensor再运算。tensor的操作和numpy中的数组操作类似，不再赘述，详见官网。下面列举一些简单例子。首先pytorch的导入是import torch，因为torch一直都是那个torch，一开始是别的语言写的，现在在python下，所以就叫pytorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126a7c8f-4e05-4f70-8347-a08b2aaeefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c25dc-a27f-473e-98a3-52cdf01369e3",
   "metadata": {},
   "source": [
    "Tensor是pytorch的基本数据类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abcfd79-d6ca-4589-9f6a-2e6b92bb133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5)\n",
    "# 如果想要从tensor中获取到长度的int数据\n",
    "type(list(x.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fa9789-b7d8-42c7-872d-7c269251b3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6175e+04, 4.5876e-41, 1.6175e+04],\n",
       "        [4.5876e-41, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.8174e+31, 1.8788e+31, 1.7220e+22],\n",
       "        [2.1715e-18, 5.3409e-08, 4.1962e-08]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建一个 5x3 的矩阵, 未初始化的:\n",
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2952f5-74a0-4793-8112-4a1b42d96a4b",
   "metadata": {},
   "source": [
    "由此可见，PyTorch提供了Tensor，其在概念上与 numpy 数组相同，也是一个n维数组, 不过PyTorch 提供了很多能在这些 Tensor 上操作的函数。\n",
    "\n",
    "任何numpy 数组的操作都可以在 PyTorch Tensor 上开展。另外不像 numpy, PyTorch Tensor 可以利用 GPU 加速他们的数字计算。\n",
    "\n",
    "要在 GPU 上运行 PyTorch 张量, 只需将其转换为新的数据类型. 下面就像以往的 numpy 例子一样, 将 PyTorch Tensor 生成的随机数据传入双层的神经网络, 手动实现网络的正向传播和反向传播:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199bf4fc-8109-4e13-9b81-f03d8a0b9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25724466.0\n",
      "1 19648036.0\n",
      "2 18203792.0\n",
      "3 18614072.0\n",
      "4 19204092.0\n",
      "5 18604492.0\n",
      "6 16287810.0\n",
      "7 12635905.0\n",
      "8 8815755.0\n",
      "9 5676179.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(10):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n",
    "    # of shape (); we can get its value as a Python number with loss.item().\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d936d1-e3f9-4539-8333-3bf136c63c80",
   "metadata": {},
   "source": [
    "综上：\n",
    "\n",
    "- 在PyTorch中，torch.Tensor是存储和变换数据的主要工具。\n",
    "- Tensor与Numpy的多维数组非常相似。\n",
    "- Tensor还提供了GPU计算和自动求梯度等更多功能，这些使Tensor更适合深度学习。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tutorial)",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
